{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3 of ys3031, EECS 6894"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our topic is \"Reseach on data augmentation with deep neural networks\". Data Augmentation is a very efficient way to enrich the traning and testing dataset when a very limited dataset only is accessible. \n",
    "\n",
    "In this project, we would like to implement the idea of this paper (https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf). Say we are training a model that predicts which artist a specific painting is composed of. We would compare the model that trained on (1) limited dataset, with only several painting for each artist and (2) expanded dataset augmented by the paper mentioned above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "model = keras.applications.resnet50.ResNet50(include_top=True,\n",
    "                                            weights='imagenet',\n",
    "                                            input_tensor=None,\n",
    "                                            input_shape=None,\n",
    "                                            pooling=None,\n",
    "                                            classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1=9472+256\n",
    "conv2a=4160+256+36928+256+16640+16640+1024+1024\n",
    "conv2b=16448+256+36928+256+16640+1024 \n",
    "conv2c= 16448+256+36928+256+16640+1024\n",
    "conv3a= 32896+512+147584+512+66048+131584+2048+2048\n",
    "conv3b= 65664+512+147584+512+66048+2048\n",
    "conv3c= 65664+512+147584+512+66048+2048                                                                 \n",
    "conv3d= 65664+512+147584+512+66048+2048\n",
    "conv4a= 131328+1024+590080+1024+263168+525312+4096+4096\n",
    "conv4b= 262400+1024+590080+1024+263168+4096\n",
    "conv4c= 262400+1024+590080+1024+263168+4096                                                                 \n",
    "conv4d= 262400+1024+590080+1024+263168+4096\n",
    "conv4e= 262400+1024+590080+1024+263168+4096\n",
    "conv4f= 262400+1024+590080+1024+263168+4096\n",
    "conv5a= 524800+2048+2359808+2048+1050624+2099200+8192+8192                                                                 \n",
    "conv5b= 1049088+2048+2359808+2048+1050624+8192                                                                 \n",
    "conv5c= 1049088+2048+2359808+2048+1050624+8192                                                                 \n",
    "convfc= 2049000\n",
    "\n",
    "conv2 = conv2a+conv2b+conv2c\n",
    "conv3 = conv3a+conv3b+conv3c+conv3c\n",
    "conv4 = conv4a+conv4b+conv4c+conv4d+conv4e+conv4f\n",
    "conv5 = conv5a+conv5b+conv5c\n",
    "\n",
    "print(\"conv1:\", conv1)\n",
    "print(\"conv2:\", conv2)\n",
    "print(\"conv3:\", conv3)\n",
    "print(\"conv4:\", conv4)\n",
    "print(\"conv5:\", conv5)\n",
    "\n",
    "print(conv1+conv2a+conv2b+conv2c+conv3a+conv3b+conv3c+conv3d+conv4a+conv4b+conv4c+conv4d+conv4e+conv4f+conv5a+conv5b+conv5c+convfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import os\n",
    "\n",
    "def data_aug(category, starname):\n",
    "    for filename in os.listdir(os.path.join(\"data_origin\", category, starname)):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            filenameandpath = os.path.join(\"data_origin\", category, starname, filename)\n",
    "            print(filenameandpath)\n",
    "            img = load_img(os.path.join(\"data_origin\", category, starname, filename))\n",
    "            img_array = img_to_array(img)\n",
    "            img_array = img_array.reshape((1,) + img_array.shape)\n",
    "            i = 0\n",
    "            datagen = ImageDataGenerator(\n",
    "                            rotation_range=40,\n",
    "                            width_shift_range=0.2,\n",
    "                            height_shift_range=0.2,\n",
    "                            shear_range=0.2,\n",
    "                            zoom_range=0.2,\n",
    "                            horizontal_flip=True,\n",
    "                            fill_mode='nearest')\n",
    "            for _ in datagen.flow(img_array, \n",
    "                                  batch_size=1, \n",
    "                                  save_to_dir=os.path.join(\"data_expanded\", category, starname), \n",
    "                                  save_prefix=starname, \n",
    "                                  save_format=\"jpeg\"):\n",
    "                i += 1\n",
    "                if i > 50:\n",
    "                    break\n",
    "                    \n",
    "data_aug(\"train\", \"jennifer\")\n",
    "data_aug(\"validation\", \"jennifer\")\n",
    "data_aug(\"train\", \"justin\")\n",
    "data_aug(\"validation\", \"justin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 993 images belonging to 2 classes.\n",
      "Found 1190 images belonging to 2 classes.\n",
      "Epoch 1/3\n",
      "40/40 [==============================] - 674s 17s/step - loss: 1.3050 - acc: 0.7390 - val_loss: 0.4963 - val_acc: 0.8000\n",
      "Epoch 2/3\n",
      "40/40 [==============================] - 655s 16s/step - loss: 0.3121 - acc: 0.8853 - val_loss: 0.2042 - val_acc: 0.9300\n",
      "Epoch 3/3\n",
      "40/40 [==============================] - 655s 16s/step - loss: 0.2052 - acc: 0.9317 - val_loss: 0.1568 - val_acc: 0.9425\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras import regularizers\n",
    "\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "train_data_dir = 'data_expanded/train'\n",
    "validation_data_dir = 'data_expanded/validation'\n",
    "epochs = 3\n",
    "batch_size = 50\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "\n",
    "model_vgg = VGG16(input_shape=input_shape, include_top=False)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(model_vgg)\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=model_vgg.output_shape[1:]))\n",
    "top_model.add(Dense(256))\n",
    "top_model.add(Activation('relu'))\n",
    "top_model.add(Dropout(0.8))\n",
    "top_model.add(Dense(1))\n",
    "top_model.add(Activation('sigmoid'))\n",
    "\n",
    "model.add(top_model)\n",
    "\n",
    "model.layers[0].trainable = False \n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // batch_size)\n",
    "\n",
    "top_model.save_weights(\"./top_model_pre_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "\n",
    "def predict_jennifer_or_justin(img_path):\n",
    "    img_selfie = load_img(img_path, target_size=(224, 224))\n",
    "    selfie_array = img_to_array(img_selfie)\n",
    "    selfie_array = selfie_array.reshape((1,) + selfie_array.shape)\n",
    "    selfie_array /= 255.0\n",
    "    result = model.predict_classes(selfie_array)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "[[1]]\n",
      "[[0]]\n"
     ]
    }
   ],
   "source": [
    "predict_jennifer_or_justin('./selfie/sunyiming.jpeg')\n",
    "predict_jennifer_or_justin('./selfie/justin.jpeg')\n",
    "predict_jennifer_or_justin('./selfie/jennifer.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "je_pic = load_img('./selfie/jennifer.jpeg', target_size=(224, 224))\n",
    "je_array = img_to_array(je_pic)\n",
    "print(je_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/foolbox/attacks/base.py:129: UserWarning: Not running the attack because the original input is already misclassified and the adversarial thus has a distance of 0.\n",
      "  warnings.warn('Not running the attack because the original input'\n"
     ]
    }
   ],
   "source": [
    "import foolbox\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "keras.backend.set_learning_phase(0)\n",
    "preprocessing = (np.array([104, 116, 123]), 1)\n",
    "fmodel = foolbox.models.KerasModel(model, bounds=(0, 255), preprocessing=preprocessing)\n",
    "\n",
    "attack = foolbox.attacks.FGSM(fmodel)\n",
    "adversarial = attack(je_array[:, :, ::-1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (224, 224, 3) (224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(type(adversarial), adversarial.shape, je_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]]\n",
      "[[0]]\n"
     ]
    }
   ],
   "source": [
    "je_array_reshaped = je_array.reshape((1,) + je_array.shape)\n",
    "adversarial_reshaped = adversarial.reshape((1,) + adversarial.shape)\n",
    "print(model.predict_classes(je_array_reshaped))\n",
    "print(model.predict_classes(adversarial_reshaped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
